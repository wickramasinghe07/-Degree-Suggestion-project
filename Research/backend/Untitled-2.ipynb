{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6742c12b55d748e797f9e4cc4c29ee07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 5.11 GiB is allocated by PyTorch, and 1.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m encodeds \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m encodeds\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(model_inputs, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m decoded \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids)\n",
      "File \u001b[1;32mc:\\Users\\sheha\\anaconda3\\envs\\Interior_v2\\Lib\\site-packages\\transformers\\modeling_utils.py:2556\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   2552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2554\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2555\u001b[0m         )\n\u001b[1;32m-> 2556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sheha\\anaconda3\\envs\\Interior_v2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sheha\\anaconda3\\envs\\Interior_v2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sheha\\anaconda3\\envs\\Interior_v2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 802 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sheha\\anaconda3\\envs\\Interior_v2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sheha\\anaconda3\\envs\\Interior_v2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\sheha\\anaconda3\\envs\\Interior_v2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 5.11 GiB is allocated by PyTorch, and 1.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"i have question : Do you have any experience with IT-related courses? i did course Fundamentals in Biasness Management my answers :Yes, I have taken several IT-related courses and find them beneficial No, I haven't taken any IT-related courses yet, but I'm considering it.Yes, but I didn't find them very useful for my career goals.No, I don't believe IT-related courses are necessary for my field of interest what shoude i select \"}\n",
    "]\n",
    "device = \"cuda\"\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "model_inputs = encodeds.to(device)\n",
    "model.to(device)\n",
    "\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from openai) (2.6.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sheha\\anaconda3\\envs\\interior_v2\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1222985982.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    spacy download en_core_web_sm\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"IT\", \"course\", \"computer science\" ,\"programing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I have taken several IT-related courses and find them beneficial.\n"
     ]
    }
   ],
   "source": [
    "courseName = \"fundamentls of python programing\"\n",
    "doc = nlp(courseName)\n",
    "for token in doc:\n",
    "    if token.text.lower() in keywords:\n",
    "        print(\"Yes, I have taken several IT-related courses and find them beneficial.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Based on your response of having taken a course in Fundamentals of Business Management, the most suitable answer in this case would be: No, I haven't taken any IT-related courses yet, but I'm considering it. This indicates that you have not pursued IT-related courses in the past, but are open to the possibility in the future.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"i have question : Do you have any experience with IT-related courses? i did course Fundamentals in Biasness Management.  answers to select : Yes, I have taken several IT-related courses and find them beneficial No, I haven't taken any IT-related courses yet, but I'm considering it.Yes, but I didn't find them very useful for my career goals.No, I don't believe IT-related courses are necessary for my field of interest what shoude i select \"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Yes, I carefully weigh the cost against the potential value and benefits.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"I have Interest In doing DS  degree , I have question : Do you consider the cost and potential value when deciding on learning opportunities?  . answers to select :Yes, I carefully weigh the cost against the potential value and benefits. , No, I prioritize learning opportunities solely based on their relevance and content,Yes, but I tend to prioritize lower-cost options even if they may have less value. , No, I believe that investing in learning is essential regardless of the cost.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Creativity, problem-solving, analytical thinking', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"my higher education stream is ART ,I'm interest in Software engineering  ,based on my Al Stream and interest  what I might have skills ,give only skills name  'skill,skill,skill' this format  ,nothing else \"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I carefully weigh the cost against the potential value and benefits.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "promt = \"I am interested in data science degree field , I want to know what are the skills I should have to start this degree . give only 5 skills in this format 'skill, ,skill'  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": promt}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Statistics, data analysis - Data science involves analyzing large datasets so a solid foundation in statistics and data analysis is crucial for interpreting and drawing insights from data.\\n\\n2. Programming, coding - Proficiency in programming languages such as Python, R, and SQL is essential for data manipulation, modeling, and visualization.\\n\\n3. Machine learning, AI - Understanding machine learning algorithms and artificial intelligence techniques is important for building predictive models and making data-driven decisions.\\n\\n4. Data visualization, storytelling - The ability to effectively visualize and communicate data insights through charts, graphs, and presentations is key in data science to impact decision-making.\\n\\n5. Problem-solving, critical thinking - Data science requires strong problem-solving abilities and critical thinking skills to identify patterns, trends, and anomalies in data to drive business decisions and strategies.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Based on your higher education in Maths and interest in AI, you likely have a strong foundation in analytical thinking, problem-solving, and mathematical reasoning. These skills are essential for a successful career in AI, as the field involves creating algorithms, analyzing data, and developing machine learning models.\n",
    "\n",
    "Additionally, your background in Maths may have equipped you with skills in areas such as statistics, linear algebra, calculus, and probability theory, which are all important in AI research and development.\n",
    "\n",
    "To further enhance your skills in AI, you may want to consider taking courses or gaining practical experience in areas such as machine learning, deep learning, natural language processing, computer vision, and data science. Building a strong foundation in programming languages such as Python, R, and Java will also be beneficial for pursuing a career in AI.\n",
    "\n",
    "Overall, with your background in Maths and interest in AI, you have a solid foundation to succeed in the field and can continue to build upon your skills to achieve your career goals.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills found in the text: ['Python', 'R']\n"
     ]
    }
   ],
   "source": [
    "skills_to_check = [\"analytical thinking\", \"problem-solving\", \"mathematical reasoning\", \"Python\", \"R\", \"Java\"]\n",
    "\n",
    "# Initialize a list to store skills found in the text\n",
    "found_skills = []\n",
    "\n",
    "# Search for each skill in the text\n",
    "for skill in skills_to_check:\n",
    "    if skill.lower() in [token.text.lower() for token in doc]:\n",
    "        found_skills.append(skill)\n",
    "\n",
    "# Print the found skills\n",
    "print(\"Skills found in the text:\", found_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Based on your background in math and interest in data science, you likely have strong analytical and problem-solving skills. You may also have a good understanding of mathematical concepts and statistical principles, which are essential for working in data science. Additionally, your background in math may have provided you with a solid foundation in programming languages such as Python or R, which are commonly used in data science. Overall, your skills in math, statistics, programming, and critical thinking make you well-suited for a career in data science.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Analytical skills, Problem-solving skills, Critical thinking skills\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Analytical skills, Problem-solving skills, Critical thinking skills\"\n",
    "\n",
    "skills_and_languages_to_check = {\n",
    "    \"analytical thinking\", \"problem-solving\", \"mathematical reasoning\",\n",
    "    \"Python\", \"R\", \"Java\", \"C/C++\", \"JavaScript\", \"Swift\", \"Kotlin\", \"HTML/CSS\",\n",
    "    \"SQL\", \"NoSQL\", \"Frontend Development\", \"Backend Development\", \"Full-stack Development\",\n",
    "    \"React\", \"Angular\", \"Vue.js\", \"Django\", \"Flask\", \"iOS Development\", \"Android Development\",\n",
    "    \"Cross-platform Development\", \"Flutter\", \"React Native\", \"Data Analysis\",\n",
    "    \"Data Visualization Tools\", \"Statistical Analysis\", \"Machine Learning Algorithms\",\n",
    "    \"Deep Learning\", \"Natural Language Processing\", \"Computer Vision\",\n",
    "    \"Object-Oriented Programming\", \"Version Control\", \"Agile Methodologies\",\n",
    "    \"Test-Driven Development\", \"Continuous Integration/Continuous Deployment\",\n",
    "    \"Network Security\", \"Cryptography\", \"Ethical Hacking\", \"Secure Coding Practices\",\n",
    "    \"Problem-solving Skills\", \"Algorithm Design and Analysis\", \"Data Structures\",\n",
    "    \"Verbal and Written Communication Skills\", \"Teamwork and Collaboration\", \"Presentation Skills\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sheha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text2\n",
    "text2_tokens = word_tokenize(text2.lower())\n",
    "\n",
    "# Initialize a set to store matching skills\n",
    "matching_skills = set()\n",
    "\n",
    "# Tokenize and convert each skill to lowercase for comparison\n",
    "for skill in skills_and_languages_to_check:\n",
    "    skill_tokens = word_tokenize(skill.lower())\n",
    "    if any(token in text2_tokens for token in skill_tokens):\n",
    "        matching_skills.add(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Presentation Skills', 'Verbal and Written Communication Skills', 'Problem-solving Skills', 'problem-solving', 'analytical thinking'}\n"
     ]
    }
   ],
   "source": [
    "print(matching_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills_and_languages_to_check = {\n",
    "#     \"analytical thinking\", \"problem-solving\", \"mathematical reasoning\",\n",
    "#     \"Python\", \"R\", \"Java\", \"C/C++\", \"JavaScript\", \"Swift\", \"Kotlin\", \"HTML/CSS\",\n",
    "#     \"SQL\", \"NoSQL\", \"Frontend Development\", \"Backend Development\", \"Full-stack Development\",\n",
    "#     \"React\", \"Angular\", \"Vue.js\", \"Django\", \"Flask\", \"iOS Development\", \"Android Development\",\n",
    "#     \"Cross-platform Development\", \"Flutter\", \"React Native\", \"Data Analysis\",\n",
    "#     \"Data Visualization Tools\", \"Statistical Analysis\", \"Machine Learning Algorithms\",\n",
    "#     \"Deep Learning\", \"Natural Language Processing\", \"Computer Vision\",\n",
    "#     \"Object-Oriented Programming\", \"Version Control\", \"Agile Methodologies\",\n",
    "#     \"Test-Driven Development\", \"Continuous Integration/Continuous Deployment\",\n",
    "#     \"Network Security\", \"Cryptography\", \"Ethical Hacking\", \"Secure Coding Practices\",\n",
    "#     \"Problem-solving Skills\", \"Algorithm Design and Analysis\", \"Data Structures\",\n",
    "#     \"Verbal and Written Communication Skills\", \"Teamwork and Collaboration\", \"Presentation Skills\"\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills and programming languages found in the text: {'mathematical reasoning', 'Java', 'Python', 'problem-solving', 'analytical thinking', 'R'}\n"
     ]
    }
   ],
   "source": [
    "skills_and_languages_to_check = {\n",
    "    \"analytical thinking\", \"problem-solving\", \"mathematical reasoning\",\n",
    "    \"Python\", \"R\", \"Java\"\n",
    "}\n",
    "# Initialize a set to store found skills and programming languages\n",
    "found_skills_and_languages = set()\n",
    "\n",
    "# Extract named entities and noun chunks and check if they match the predefined skills and programming languages\n",
    "for entity in doc.ents:\n",
    "    if entity.text.lower() in skills_and_languages_to_check:\n",
    "        found_skills_and_languages.add(entity.text)\n",
    "for skill in skills_and_languages_to_check:\n",
    "    if skill.lower() in [token.text.lower() for token in doc]:\n",
    "        found_skills_and_languages.add(skill)\n",
    "for chunk in doc.noun_chunks:\n",
    "    if chunk.text.lower() in skills_and_languages_to_check:\n",
    "        found_skills_and_languages.add(chunk.text)\n",
    "\n",
    "# Print the found skills and programming languages\n",
    "print(\"Skills and programming languages found in the text:\", found_skills_and_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_and_languages_string = ', '.join(found_skills_and_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python, R, problem-solving, Java, mathematical reasoning, analytical thinking'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_and_languages_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Define sets to store skills and programming languages\n",
    "skills = set()\n",
    "programming_languages = set()\n",
    "\n",
    "# Extract skills and programming languages using named entity recognition (NER)\n",
    "for entity in doc.ents:\n",
    "    if entity.label_ == \"SKILL\":\n",
    "        skills.add(entity.text)\n",
    "    elif entity.label_ == \"PROGRAMMING_LANGUAGE\":\n",
    "        programming_languages.add(entity.text)\n",
    "\n",
    "# Convert sets to lists for easier handling\n",
    "skills_list = list(skills)\n",
    "programming_languages_list = list(programming_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cv' is not in the list of interests.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class InterestSkillMapper:\n",
    "    def __init__(self, interest_embeddings, skill_embeddings, interests, skills):\n",
    "        self.interest_embeddings = interest_embeddings\n",
    "        self.skill_embeddings = skill_embeddings\n",
    "        self.interests = interests\n",
    "        self.skills = skills\n",
    "\n",
    "    def get_skills_for_interest(self, interest):\n",
    "        if interest not in self.interests:\n",
    "            return []\n",
    "\n",
    "        interest_index = self.interests.index(interest)\n",
    "        interest_embedding = self.interest_embeddings[interest_index].reshape(1, -1)\n",
    "        similarities = cosine_similarity(interest_embedding, self.skill_embeddings)\n",
    "        most_similar_skill_index = np.argmax(similarities)\n",
    "        return self.skills[most_similar_skill_index]\n",
    "\n",
    "    def check_interest_exists(self, interest):\n",
    "        return interest in self.interests\n",
    "\n",
    "# Example usage:\n",
    "# Example randomly generated embeddings (replace with actual embeddings)\n",
    "interest_embeddings = np.random.rand(5, 100)\n",
    "skill_embeddings = np.random.rand(5, 100)\n",
    "\n",
    "interests = [\"AI\", \"Data Science\", \"Software Engineering\", \"Machine Learning\", \"Network Security\", \"Robotics\", \"Natural Language Processing\", \"Cybersecurity\", \"Computer Vision\"]\n",
    "\n",
    "skills = [\n",
    "    [\"Machine Learning Algorithms\", \"Deep Learning\", \"Natural Language Processing\", \"Data Analysis\", \"TensorFlow\", \"PyTorch\", \"Scikit-learn\"],\n",
    "    [\"Data Analysis\", \"Data Visualization Tools\", \"Statistical Analysis\", \"Python (pandas, numpy, matplotlib)\", \"R\", \"Tableau\"],\n",
    "    [\"Python\", \"Java\", \"C/C++\", \"JavaScript\", \"Version Control\", \"Agile Methodologies\", \"Test-Driven Development\"],\n",
    "    [\"Python\", \"R\", \"Machine Learning Algorithms\", \"Deep Learning\", \"Statistical Analysis\"],\n",
    "    [\"Network Security\", \"Cryptography\", \"Ethical Hacking\", \"Secure Coding Practices\", \"Wireshark\", \"Nmap\", \"Metasploit\"],\n",
    "    [\"Robotics Programming\", \"Control Systems\", \"ROS (Robot Operating System)\", \"Computer Vision\", \"Embedded Systems\"],\n",
    "    [\"Natural Language Processing\", \"Text Mining\", \"Chatbot Development\", \"Word Embeddings\", \"NLTK\", \"SpaCy\"],\n",
    "    [\"Cybersecurity Fundamentals\", \"Penetration Testing\", \"Digital Forensics\", \"Security Protocols\", \"Firewalls\"],\n",
    "    [\"Computer Vision\", \"Image Processing\", \"Object Detection\", \"OpenCV\", \"Deep Learning for Computer Vision\"]\n",
    "]\n",
    "\n",
    "interest_skill_mapper = InterestSkillMapper(interest_embeddings, skill_embeddings, interests, skills)\n",
    "\n",
    "# Get relevant skills for an interest\n",
    "interest = \"cv\"\n",
    "if interest_skill_mapper.check_interest_exists(interest):\n",
    "    relevant_skills = interest_skill_mapper.get_skills_for_interest(interest)\n",
    "    print(f\"Relevant skills for interest '{interest}': {relevant_skills}\")\n",
    "else:\n",
    "    print(f\"'{interest}' is not in the list of interests.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADHD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
